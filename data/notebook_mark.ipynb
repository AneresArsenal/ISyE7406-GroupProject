{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold \n",
    "from sklearn.metrics import  confusion_matrix, f1_score, make_scorer, recall_score\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('journeys.csv') \n",
    "targets = df['Conversion'] \n",
    "df.drop(['Journey Start Date', 'Journey End Date', 'Events Combo', 'User-Journey'], axis=1, inplace=True) \n",
    "df = pd.get_dummies(df) \n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, test_size=0.3) \n",
    "X_train.drop(['Conversion'], axis=1, inplace=True) \n",
    "X_test.drop(['Conversion'], axis=1, inplace=True) \n",
    "\n",
    "scaler = StandardScaler() \n",
    "scaler.fit(X_train) \n",
    " \n",
    "s_X_train = scaler.transform(X_train) \n",
    "s_X_test = scaler.transform(X_test) \n",
    "\n",
    "X_train = pd.DataFrame(s_X_train, columns = X_train.columns)\n",
    "X_test = pd.DataFrame(s_X_test, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'min_samples_split': [3, 5, 10],  \n",
    "    'n_estimators' : [300], \n",
    "    'max_depth': [3, 5, 15, 25], \n",
    "    'max_features': [3, 5, 10, 19]\n",
    "\n",
    "} \n",
    "  \n",
    "#https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65  \n",
    "def grid_search_wrapper(_model = '', refit_score='fb_score', param_grid=param_grid): \n",
    "    \"\"\" \n",
    "    fits a GridSearchCV classifier using refit_score for optimization \n",
    "    prints classifier performance metrics \n",
    "    \"\"\" \n",
    "    grid_search = GridSearchCV(_model, param_grid, scoring=make_scorer(f1_score), refit=refit_score, \n",
    "        return_train_score=True, n_jobs=-1, error_score='raise', cv=10) \n",
    "    grid_search.fit(X_train.values, y_train.values) \n",
    " \n",
    "    # make the predictions \n",
    "    y_pred = grid_search.predict(X_test.values) \n",
    " \n",
    "    print('Best params for {}'.format(refit_score)) \n",
    "    print(grid_search.best_params_) \n",
    " \n",
    "    # confusion matrix on the test data. \n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score)) \n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos'])) \n",
    "    return grid_search\n",
    "\n",
    "def show_model_output(grid_search_output, num_to_show = 10): \n",
    "    try:\n",
    "        df1 = pd.DataFrame(grid_search_output.cv_results_['params'])\n",
    "        df2 = pd.DataFrame(grid_search_output.cv_results_['mean_train_score']).rename(columns={0: \"mean_train_score\"})\n",
    "        df3 = pd.DataFrame(grid_search_output.cv_results_['mean_test_score']).rename(columns={0: \"mean_test_score\"})\n",
    "        result = pd.concat([df2,df3,df1], axis = 1).sort_values(by='mean_test_score', ascending=False)\n",
    "        result = result.head(num_to_show)\n",
    "    except Exception:\n",
    "    ## for some reason logistic regression doesnt have mean_train_score\n",
    "        df1 = pd.DataFrame(grid_search_output.cv_results_['params'])\n",
    "        df3 = pd.DataFrame(grid_search_output.cv_results_['mean_test_score']).rename(columns={0: \"mean_test_score\"})\n",
    "        result = pd.concat([df3,df1], axis = 1).sort_values(by='mean_test_score', ascending=False)\n",
    "        result = result.head(num_to_show)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "grid_search_clf = grid_search_wrapper(_model = clf, refit_score='fb_score', param_grid=param_grid) \n",
    "#y_scores = grid_search_clf.predict_proba(X_test)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_model_output(grid_search_output= grid_search_clf, num_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.logspace(-3, 3, 7),\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "140 fits failed out of a total of 420.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "70 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.         0.00519481 0.00519481 0.11823025\n",
      "        nan        nan 0.06583096 0.34752473 0.34752473 0.37354056\n",
      "        nan        nan 0.41267968 0.41214699 0.41214699 0.41354072\n",
      "        nan        nan 0.41801146 0.41759068 0.41759068 0.41759068\n",
      "        nan        nan 0.42074928 0.42074928 0.42074928 0.42074928\n",
      "        nan        nan 0.42074928 0.42074928 0.42074928 0.42074928\n",
      "        nan        nan 0.42074928 0.42074928 0.42074928 0.42074928]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03]),\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear']},\n",
       "             scoring=make_scorer(f1_score))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=42)\n",
    "log_reg = GridSearchCV(logreg, param_grid=param_grid, scoring=make_scorer(f1_score), cv=10)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>100.0</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.420749</td>\n",
       "      <td>10.0</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score       C penalty     solver\n",
       "41         0.420749  1000.0      l2  liblinear\n",
       "40         0.420749  1000.0      l2      lbfgs\n",
       "39         0.420749  1000.0      l2  newton-cg\n",
       "38         0.420749  1000.0      l1  liblinear\n",
       "35         0.420749   100.0      l2  liblinear\n",
       "34         0.420749   100.0      l2      lbfgs\n",
       "33         0.420749   100.0      l2  newton-cg\n",
       "32         0.420749   100.0      l1  liblinear\n",
       "29         0.420749    10.0      l2  liblinear\n",
       "28         0.420749    10.0      l2      lbfgs"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_model_output(grid_search_output= log_reg, num_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/tilii7/hyperparameter-grid-search-with-xgboost/notebook\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:38:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"C\", \"penalty\", \"silent\", \"solver\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[10:38:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best params for fb_score\n",
      "{'C': 0.001, 'penalty': 'l1', 'solver': 'newton-cg'}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for fb_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1948        10\n",
      "pos       115       165\n"
     ]
    }
   ],
   "source": [
    "grid_search_xgb = grid_search_wrapper(_model = xgb, refit_score='fb_score', param_grid=param_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>C</th>\n",
       "      <th>penalty</th>\n",
       "      <th>solver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>0.001</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>100.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>1.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>10.000</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.728605</td>\n",
       "      <td>0.697394</td>\n",
       "      <td>100.000</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_train_score  mean_test_score        C penalty     solver\n",
       "0           0.728605         0.697394    0.001      l1  newton-cg\n",
       "31          0.728605         0.697394  100.000      l1      lbfgs\n",
       "23          0.728605         0.697394    1.000      l2  liblinear\n",
       "24          0.728605         0.697394   10.000      l1  newton-cg\n",
       "25          0.728605         0.697394   10.000      l1      lbfgs\n",
       "26          0.728605         0.697394   10.000      l1  liblinear\n",
       "27          0.728605         0.697394   10.000      l2  newton-cg\n",
       "28          0.728605         0.697394   10.000      l2      lbfgs\n",
       "29          0.728605         0.697394   10.000      l2  liblinear\n",
       "30          0.728605         0.697394  100.000      l1  newton-cg"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_model_output(grid_search_output= grid_search_xgb, num_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search_clf.best_estimator_.fit(X_train, y_train)\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_train, plot_type = 'bar', class_names=model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_train, class_names=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search_lr.best_estimator_.fit(X_train, y_train)\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\", class_names=model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", class_names=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBooost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = grid_search_xgb.best_estimator_.fit(X_train, y_train)\n",
    "explainer = shap.Explainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\", class_names=model.classes_)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35621b5f5adf8bc7b76cd61c0e64075e09b8e2c83dd392c0c22200df920c13e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
