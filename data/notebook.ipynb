{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold \n",
    "from sklearn.metrics import  confusion_matrix, f1_score, make_scorer, recall_score\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('journeys.csv') \n",
    "targets = df['Conversion'] \n",
    "df.drop(['Journey Start Date', 'Journey End Date', 'Events Combo', 'User-Journey'], axis=1, inplace=True) \n",
    "df = pd.get_dummies(df) \n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, stratify=targets) \n",
    "X_train.drop(['Conversion'], axis=1, inplace=True) \n",
    "X_test.drop(['Conversion'], axis=1, inplace=True) \n",
    "\n",
    "#scaler = StandardScaler() \n",
    "#scaler.fit(X_train) \n",
    " \n",
    "#X_train = scaler.transform(X_train) \n",
    "#X_test = scaler.transform(X_test) b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for fb_score\n",
      "{'max_depth': 15, 'max_features': 19, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for fb_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1597         8\n",
      "pos       122       138\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "    'min_samples_split': [3, 5, 10],  \n",
    "    'n_estimators' : [300], \n",
    "    'max_depth': [3, 5, 15, 25], \n",
    "    'max_features': [3, 5, 10, 19]\n",
    "\n",
    "} \n",
    "  \n",
    "def grid_search_wrapper(clf = '', refit_score='fb_score', param_grid=param_grid): \n",
    "    \"\"\" \n",
    "    fits a GridSearchCV classifier using refit_score for optimization \n",
    "    prints classifier performance metrics \n",
    "    \"\"\" \n",
    "    skf = StratifiedKFold(n_splits=10) \n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=make_scorer(f1_score), refit=refit_score, \n",
    "                           cv=skf, return_train_score=True, n_jobs=-1) \n",
    "    grid_search.fit(X_train.values, y_train.values) \n",
    " \n",
    "    # make the predictions \n",
    "    y_pred = grid_search.predict(X_test.values) \n",
    " \n",
    "    print('Best params for {}'.format(refit_score)) \n",
    "    print(grid_search.best_params_) \n",
    " \n",
    "    # confusion matrix on the test data. \n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score)) \n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos'])) \n",
    "    return grid_search\n",
    "\n",
    "def show_model_output(grid_search_output): \n",
    "    df1 = pd.DataFrame(grid_search_output.cv_results_['params'])\n",
    "    df2 = pd.DataFrame(grid_search_output.cv_results_['mean_train_score']).rename(columns={0: \"mean_train_score\"})\n",
    "    df3 = pd.DataFrame(grid_search_output.cv_results_['mean_test_score']).rename(columns={0: \"mean_test_score\"})\n",
    "    result = pd.concat([df2,df3,df1], axis = 1).sort_values(by='mean_test_score', ascending=False)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "grid_search_clf = grid_search_wrapper(clf = clf, refit_score='fb_score') \n",
    "#y_scores = grid_search_clf.predict_proba(X_test)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.733653</td>\n",
       "      <td>0.713308</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.735499</td>\n",
       "      <td>0.712731</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.733327</td>\n",
       "      <td>0.711813</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.733723</td>\n",
       "      <td>0.711118</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.732827</td>\n",
       "      <td>0.710578</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.707886</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.734837</td>\n",
       "      <td>0.706866</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.709923</td>\n",
       "      <td>0.706478</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.709923</td>\n",
       "      <td>0.706478</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.748804</td>\n",
       "      <td>0.706221</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.748875</td>\n",
       "      <td>0.706119</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.752258</td>\n",
       "      <td>0.705993</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.753136</td>\n",
       "      <td>0.705682</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.758712</td>\n",
       "      <td>0.704964</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.747885</td>\n",
       "      <td>0.704598</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.709479</td>\n",
       "      <td>0.704199</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.754621</td>\n",
       "      <td>0.702225</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.736087</td>\n",
       "      <td>0.701887</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.761570</td>\n",
       "      <td>0.700512</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.763039</td>\n",
       "      <td>0.699988</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.766495</td>\n",
       "      <td>0.699068</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.758146</td>\n",
       "      <td>0.698420</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.769501</td>\n",
       "      <td>0.697263</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.776892</td>\n",
       "      <td>0.694553</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.702338</td>\n",
       "      <td>0.694303</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.775241</td>\n",
       "      <td>0.694271</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.702588</td>\n",
       "      <td>0.694178</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.775902</td>\n",
       "      <td>0.692546</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.701577</td>\n",
       "      <td>0.692517</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.775581</td>\n",
       "      <td>0.690203</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.663224</td>\n",
       "      <td>0.661994</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.663224</td>\n",
       "      <td>0.661994</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.663224</td>\n",
       "      <td>0.661994</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.639977</td>\n",
       "      <td>0.627258</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.635554</td>\n",
       "      <td>0.625832</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.631068</td>\n",
       "      <td>0.623250</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.619841</td>\n",
       "      <td>0.621227</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.611167</td>\n",
       "      <td>0.609428</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.613400</td>\n",
       "      <td>0.608828</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.457784</td>\n",
       "      <td>0.454220</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.455431</td>\n",
       "      <td>0.452735</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.455091</td>\n",
       "      <td>0.452675</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.428942</td>\n",
       "      <td>0.427692</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.424755</td>\n",
       "      <td>0.424443</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.424921</td>\n",
       "      <td>0.422867</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233716</td>\n",
       "      <td>0.236522</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.216237</td>\n",
       "      <td>0.223848</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.211431</td>\n",
       "      <td>0.209417</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_train_score  mean_test_score  max_depth  max_features  \\\n",
       "35          0.733653         0.713308         15            19   \n",
       "47          0.735499         0.712731         25            19   \n",
       "29          0.733327         0.711813         15             5   \n",
       "44          0.733723         0.711118         25            10   \n",
       "32          0.732827         0.710578         15            10   \n",
       "26          0.733000         0.707886         15             3   \n",
       "41          0.734837         0.706866         25             5   \n",
       "21          0.709923         0.706478          5            19   \n",
       "22          0.709923         0.706478          5            19   \n",
       "31          0.748804         0.706221         15            10   \n",
       "28          0.748875         0.706119         15             5   \n",
       "43          0.752258         0.705993         25            10   \n",
       "34          0.753136         0.705682         15            19   \n",
       "46          0.758712         0.704964         25            19   \n",
       "25          0.747885         0.704598         15             3   \n",
       "23          0.709479         0.704199          5            19   \n",
       "40          0.754621         0.702225         25             5   \n",
       "38          0.736087         0.701887         25             3   \n",
       "24          0.761570         0.700512         15             3   \n",
       "27          0.763039         0.699988         15             5   \n",
       "30          0.766495         0.699068         15            10   \n",
       "37          0.758146         0.698420         25             3   \n",
       "33          0.769501         0.697263         15            19   \n",
       "45          0.776892         0.694553         25            19   \n",
       "19          0.702338         0.694303          5            10   \n",
       "36          0.775241         0.694271         25             3   \n",
       "18          0.702588         0.694178          5            10   \n",
       "42          0.775902         0.692546         25            10   \n",
       "20          0.701577         0.692517          5            10   \n",
       "39          0.775581         0.690203         25             5   \n",
       "9           0.663224         0.661994          3            19   \n",
       "11          0.663224         0.661994          3            19   \n",
       "10          0.663224         0.661994          3            19   \n",
       "15          0.639977         0.627258          5             5   \n",
       "16          0.635554         0.625832          5             5   \n",
       "17          0.631068         0.623250          5             5   \n",
       "8           0.619841         0.621227          3            10   \n",
       "6           0.611167         0.609428          3            10   \n",
       "7           0.613400         0.608828          3            10   \n",
       "13          0.457784         0.454220          5             3   \n",
       "12          0.455431         0.452735          5             3   \n",
       "14          0.455091         0.452675          5             3   \n",
       "5           0.428942         0.427692          3             5   \n",
       "3           0.424755         0.424443          3             5   \n",
       "4           0.424921         0.422867          3             5   \n",
       "2           0.233716         0.236522          3             3   \n",
       "0           0.216237         0.223848          3             3   \n",
       "1           0.211431         0.209417          3             3   \n",
       "\n",
       "    min_samples_split  n_estimators  \n",
       "35                 10           300  \n",
       "47                 10           300  \n",
       "29                 10           300  \n",
       "44                 10           300  \n",
       "32                 10           300  \n",
       "26                 10           300  \n",
       "41                 10           300  \n",
       "21                  3           300  \n",
       "22                  5           300  \n",
       "31                  5           300  \n",
       "28                  5           300  \n",
       "43                  5           300  \n",
       "34                  5           300  \n",
       "46                  5           300  \n",
       "25                  5           300  \n",
       "23                 10           300  \n",
       "40                  5           300  \n",
       "38                 10           300  \n",
       "24                  3           300  \n",
       "27                  3           300  \n",
       "30                  3           300  \n",
       "37                  5           300  \n",
       "33                  3           300  \n",
       "45                  3           300  \n",
       "19                  5           300  \n",
       "36                  3           300  \n",
       "18                  3           300  \n",
       "42                  3           300  \n",
       "20                 10           300  \n",
       "39                  3           300  \n",
       "9                   3           300  \n",
       "11                 10           300  \n",
       "10                  5           300  \n",
       "15                  3           300  \n",
       "16                  5           300  \n",
       "17                 10           300  \n",
       "8                  10           300  \n",
       "6                   3           300  \n",
       "7                   5           300  \n",
       "13                  5           300  \n",
       "12                  3           300  \n",
       "14                 10           300  \n",
       "5                  10           300  \n",
       "3                   3           300  \n",
       "4                   5           300  \n",
       "2                  10           300  \n",
       "0                   3           300  \n",
       "1                   5           300  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_model_output(grid_search_output= grid_search_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35621b5f5adf8bc7b76cd61c0e64075e09b8e2c83dd392c0c22200df920c13e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
