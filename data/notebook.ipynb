{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    " \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold \n",
    "from sklearn.metrics import  confusion_matrix, f1_score, make_scorer, recall_score\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df = pd.read_csv('journeys.csv') \n",
    "targets = df['Conversion'] \n",
    "df.drop(['Journey Start Date', 'Journey End Date', 'Events Combo', 'User-Journey'], axis=1, inplace=True) \n",
    "df = pd.get_dummies(df) \n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, stratify=targets) \n",
    "X_train.drop(['Conversion'], axis=1, inplace=True) \n",
    "X_test.drop(['Conversion'], axis=1, inplace=True) \n",
    "\n",
    "#scaler = StandardScaler() \n",
    "#scaler.fit(X_train) \n",
    " \n",
    "#X_train = scaler.transform(X_train) \n",
    "#X_test = scaler.transform(X_test) b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'min_samples_split': [3, 5, 10],  \n",
    "    'n_estimators' : [300], \n",
    "    'max_depth': [3, 5, 15, 25], \n",
    "    'max_features': [3, 5, 10, 19]\n",
    "\n",
    "} \n",
    "  \n",
    "def grid_search_wrapper(_model = '', refit_score='fb_score', param_grid=param_grid): \n",
    "    \"\"\" \n",
    "    fits a GridSearchCV classifier using refit_score for optimization \n",
    "    prints classifier performance metrics \n",
    "    \"\"\" \n",
    "    skf = StratifiedKFold(n_splits=10) \n",
    "    grid_search = GridSearchCV(_model, param_grid, scoring=make_scorer(f1_score), refit=refit_score, \n",
    "                           cv=skf, return_train_score=True, n_jobs=-1, error_score='raise') \n",
    "    grid_search.fit(X_train.values, y_train.values) \n",
    " \n",
    "    # make the predictions \n",
    "    y_pred = grid_search.predict(X_test.values) \n",
    " \n",
    "    print('Best params for {}'.format(refit_score)) \n",
    "    print(grid_search.best_params_) \n",
    " \n",
    "    # confusion matrix on the test data. \n",
    "    print('\\nConfusion matrix of Random Forest optimized for {} on the test data:'.format(refit_score)) \n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                 columns=['pred_neg', 'pred_pos'], index=['neg', 'pos'])) \n",
    "    return grid_search\n",
    "\n",
    "def show_model_output(grid_search_output, num_to_show = 10): \n",
    "    df1 = pd.DataFrame(grid_search_output.cv_results_['params'])\n",
    "    df2 = pd.DataFrame(grid_search_output.cv_results_['mean_train_score']).rename(columns={0: \"mean_train_score\"})\n",
    "    df3 = pd.DataFrame(grid_search_output.cv_results_['mean_test_score']).rename(columns={0: \"mean_test_score\"})\n",
    "    result = pd.concat([df2,df3,df1], axis = 1).sort_values(by='mean_test_score', ascending=False)\n",
    "    result = result.head(num_to_show)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for fb_score\n",
      "{'max_depth': 15, 'max_features': 10, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for fb_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1598         7\n",
      "pos       110       150\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1)\n",
    "grid_search_clf = grid_search_wrapper(_model = clf, refit_score='fb_score', param_grid=param_grid) \n",
    "#y_scores = grid_search_clf.predict_proba(X_test)[:, 1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.718585</td>\n",
       "      <td>0.693738</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.694607</td>\n",
       "      <td>0.691036</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.722778</td>\n",
       "      <td>0.690112</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.718138</td>\n",
       "      <td>0.689929</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.717524</td>\n",
       "      <td>0.689854</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.716529</td>\n",
       "      <td>0.689224</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.737654</td>\n",
       "      <td>0.687999</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.693772</td>\n",
       "      <td>0.687967</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.692815</td>\n",
       "      <td>0.687967</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.734711</td>\n",
       "      <td>0.686524</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_train_score  mean_test_score  max_depth  max_features  \\\n",
       "32          0.718585         0.693738         15            10   \n",
       "22          0.694607         0.691036          5            19   \n",
       "47          0.722778         0.690112         25            19   \n",
       "44          0.718138         0.689929         25            10   \n",
       "41          0.717524         0.689854         25             5   \n",
       "29          0.716529         0.689224         15             5   \n",
       "31          0.737654         0.687999         15            10   \n",
       "21          0.693772         0.687967          5            19   \n",
       "23          0.692815         0.687967          5            19   \n",
       "28          0.734711         0.686524         15             5   \n",
       "\n",
       "    min_samples_split  n_estimators  \n",
       "32                 10           300  \n",
       "22                  5           300  \n",
       "47                 10           300  \n",
       "44                 10           300  \n",
       "41                 10           300  \n",
       "29                 10           300  \n",
       "31                  5           300  \n",
       "21                  3           300  \n",
       "23                 10           300  \n",
       "28                  5           300  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_model_output(grid_search_output= grid_search_clf, num_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "     'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "     'l1_ratio': [0, .25, .5, .75, 1]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for fb_score\n",
      "{'l1_ratio': 1, 'penalty': 'elasticnet'}\n",
      "\n",
      "Confusion matrix of Random Forest optimized for fb_score on the test data:\n",
      "     pred_neg  pred_pos\n",
      "neg      1605         0\n",
      "pos       194        66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mark\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, solver='saga')\n",
    "grid_search_lr = grid_search_wrapper(_model = logreg, refit_score='fb_score', param_grid=param_grid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>l1_ratio</th>\n",
       "      <th>penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.419341</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>0.00</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.419341</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>0.25</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.419341</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>0.50</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.419341</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>0.75</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.419341</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>1.00</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.419341</td>\n",
       "      <td>0.414091</td>\n",
       "      <td>1.00</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.416935</td>\n",
       "      <td>0.409374</td>\n",
       "      <td>0.75</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.416857</td>\n",
       "      <td>0.407908</td>\n",
       "      <td>0.50</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.415421</td>\n",
       "      <td>0.406161</td>\n",
       "      <td>0.25</td>\n",
       "      <td>elasticnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413592</td>\n",
       "      <td>0.401792</td>\n",
       "      <td>0.00</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_train_score  mean_test_score  l1_ratio     penalty\n",
       "0           0.419341         0.414091      0.00          l1\n",
       "3           0.419341         0.414091      0.25          l1\n",
       "6           0.419341         0.414091      0.50          l1\n",
       "9           0.419341         0.414091      0.75          l1\n",
       "12          0.419341         0.414091      1.00          l1\n",
       "14          0.419341         0.414091      1.00  elasticnet\n",
       "11          0.416935         0.409374      0.75  elasticnet\n",
       "8           0.416857         0.407908      0.50  elasticnet\n",
       "5           0.415421         0.406161      0.25  elasticnet\n",
       "1           0.413592         0.401792      0.00          l2"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_model_output(grid_search_output= grid_search_lr, num_to_show=10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f35621b5f5adf8bc7b76cd61c0e64075e09b8e2c83dd392c0c22200df920c13e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
